from src.models.gemma_3_4b import call_vllm_api
from src.vector_db.vector_searcher import search_similar_documents, get_user_joined_group_ids
from src.models.gemma_3_4b import generate_explaination
import json
from src.core.ai_logger import get_ai_logger

ai_logger = get_ai_logger()

async def handle_combined_question(answer: str | None, user_id: str, session_id: str) -> dict:
    """
    ì´ì „ ë‹µë³€(answer)ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬
    question + optionsë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    prompt = generate_combined_prompt(answer)

    try:
        raw_response = await call_vllm_api(prompt)

        # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ì œê±° ë° ì •ì œ
        cleaned = raw_response.strip().removeprefix("```json").removesuffix("```").strip()
        parsed = json.loads(cleaned)

        question = parsed.get("question", "").strip()
        options = parsed.get("options", [])

        if not question or not isinstance(options, list) or len(options) < 2:
            raise ValueError("ì§ˆë¬¸ ë˜ëŠ” ë³´ê¸° ìƒì„± ì‹¤íŒ¨")

        ai_logger.info("[Chatbot] ì§ˆë¬¸ ìƒì„± ì„±ê³µ", extra={
            "user_id": user_id,
            "session_id": session_id,
            "question": question
        })

        return {
            "question": question,
            "options": options
        }

    except Exception as e:
        ai_logger.warning("[Chatbot] ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨", extra={
            "user_id": user_id,
            "session_id": session_id,
            "error": str(e)
        })

        return {
            "question": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.",
            "options": []
        }

def generate_combined_prompt(previous_answer: str | None) -> str:
    """
    ì‚¬ìš©ìì˜ ì´ì „ ì‘ë‹µì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ê³¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ ,
    ì—†ë‹¤ë©´ ëª¨ì„ ì„±í–¥ íŒŒì•…ì„ ìœ„í•œ ì²« ì§ˆë¬¸ì„ êµ¬ì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ìƒì„±ëœ ì§ˆë¬¸ì€ ì¶”ì²œí•  ëª¨ì„ì„ ë” ì •í™•íˆ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    """

    if previous_answer:
        intro = (
            f"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ëª¨ì„ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.\n"
            f"ì‚¬ìš©ìê°€ ì´ì „ì— ì•„ë˜ì™€ ê°™ì´ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤:\n\n"
            f"\"{previous_answer}\"\n\n"
            f"ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ì‚¬ìš©ìì˜ ì„±í–¥ì´ë‚˜ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•˜ì—¬ ëª¨ì„ì„ ë” ì˜ ì¶”ì²œí•  ìˆ˜ ìˆë„ë¡\n"
            f"ì´ì–´ì§€ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ê³¼ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"
        )
    else:
        intro = (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ëª¨ì„ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.\n"
            "ì‚¬ìš©ìê°€ ì²˜ìŒ ì§ˆë¬¸ì— ì‘ë‹µí•˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤.\n"
            "ì‚¬ìš©ìì˜ ëª¨ì„ ì°¸ì—¬ ì„±í–¥ì´ë‚˜ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´\n"
            "ì ì ˆí•œ ì²« ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.\n"
        )

    instruction = (
        "ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n\n"
        "{\n"
        "  \"question\": \"ìì—°ìŠ¤ëŸ¬ìš´ ë„ì… ë¬¸ì¥ê³¼ í•¨ê»˜ ì´ì–´ì§€ëŠ” ì§ˆë¬¸\",\n"
        "  \"options\": [\"ì„ íƒì§€1\", \"ì„ íƒì§€2\", \"ì„ íƒì§€3\", \"ì„ íƒì§€4\"]\n"
        "}\n\n"
        "ì§ˆë¬¸ì€ ì¶”ì²œí•  ëª¨ì„ì„ ê³ ë¥¼ ë•Œ ë„ì›€ì´ ë  ìˆ˜ ìˆë„ë¡\n"
        "ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬, í™œë™ ìŠ¤íƒ€ì¼, ì‹œê°„ëŒ€, ì‚¬ëŒê³¼ì˜ êµë¥˜ ë°©ì‹ ë“±ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ë‹¤ë¤„ì•¼ í•©ë‹ˆë‹¤.\n"
        "ì§ˆë¬¸ ê¸¸ì´ëŠ” ì•½ 100ì ì´ë‚´ë¡œ ì œí•œí•©ë‹ˆë‹¤.\n"
        "ë¬¸ì¥ì€ ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²˜ëŸ¼ ì‹œì‘í•˜ê³ , ë§ˆì§€ë§‰ì— ì§ˆë¬¸ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.\n"
        "ì„ íƒì§€ëŠ” 4ê°œë¡œ êµ¬ì„±í•˜ê³ , ê°ê°ì€ ëª…í™•í•˜ê³  ì¤‘ë³µë˜ì§€ ì•Šìœ¼ë©° 4ë‹¨ì–´ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
    )

    return intro + instruction

async def handle_answer_analysis(messages: list[dict], user_id: str, session_id: str, debug = False) -> dict:
    """
    ì „ì²´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì™€ ì¶”ì²œ ê·¸ë£¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
    ì‚¬ìš©ìê°€ ê°€ì…í•˜ì§€ ì•Šì€ ê·¸ë£¹ ì¤‘ í•˜ë‚˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    """

    if not messages:
        ai_logger.warning("[ì¶”ì²œ] ë¹ˆ ë©”ì‹œì§€ ìˆ˜ì‹ ", extra={"session_id": session_id})
        return {
            "groupId": -1,
            "reason": "ëŒ€í™” ë‚´ìš©ì´ ë¶€ì¡±í•˜ì—¬ ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }

    # 1. ëŒ€í™” ë‚´ìš©ì„ ê²°í•©
    combined_text = "\n".join([f"{m['role']}: {m['text']}" for m in messages])
    ai_logger.info("[ì¶”ì²œ] ë©”ì‹œì§€ ë³‘í•© ì™„ë£Œ", extra={"session_id": session_id})

    # 2. ì°¸ì—¬ ê·¸ë£¹ í•„í„°ë§ (user_idëŠ” ì„¸ì…˜ìœ¼ë¡œë¶€í„° ì¶”ë¡  ê°€ëŠ¥í•˜ë‹¤ëŠ” ì „ì œ)
    try:
        joined_ids = get_user_joined_group_ids(user_id)
    except Exception:
        joined_ids = set()
        ai_logger.warning("[ì¶”ì²œ] ìœ ì € ì°¸ì—¬ ê·¸ë£¹ ì¡°íšŒ ì‹¤íŒ¨", extra={"session_id": session_id})

    # 3. ìœ ì‚¬ ê·¸ë£¹ ê²€ìƒ‰
    results = search_similar_documents(combined_text, top_k=10)
    filtered = [
        r for r in results
        if r.get("metadata", {}).get("groupId") not in joined_ids
           and r.get("metadata", {}).get("groupId") is not None
    ]

    if debug:
        print("ğŸ” ê²€ìƒ‰ ê²°ê³¼:", len(results))
        print("âœ… í•„í„°ë§ í›„:", len(filtered))

    if not filtered:
        return {
            "groupId": -1,
            "reason": "ì¶”ì²œ ê°€ëŠ¥í•œ ìƒˆë¡œìš´ ëª¨ì„ì´ ì•„ì§ ì—†ì–´ìš”. ì§ì ‘ ë¹„ìŠ·í•œ ëª¨ì„ì„ ì—´ì–´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
        }

    # 4. ì¶”ì²œ ëŒ€ìƒ ì„ ì •
    top_result = filtered[0]
    group_id = int(top_result["metadata"]["groupId"])
    group_text = top_result["text"]

    # 5. LLM ê¸°ë°˜ ì¶”ì²œ ì‚¬ìœ  ìƒì„±
    try:
        reason = await generate_explaination(messages, group_text)
        ai_logger.info("[ì¶”ì²œ] ì¶”ì²œ ì‚¬ìœ  ìƒì„± ì™„ë£Œ", extra={"group_id": group_id})
    except Exception:
        reason = "ì´ ëª¨ì„ì€ ë‹¹ì‹ ì˜ ëŒ€í™” ë‚´ìš©ê³¼ ê°€ì¥ ì˜ ì–´ìš¸ë ¤ ì¶”ì²œë“œë¦½ë‹ˆë‹¤."
        ai_logger.warning("[ì¶”ì²œ] ì¶”ì²œ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨", extra={"group_id": group_id})

    return {
        "groupId": group_id,
        "reason": reason
    }
